{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOWtFyDI2bdGWErUN19b6UF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itonse/google-colab-archive/blob/main/goohaeyou_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYFgpQPyVRgf",
        "outputId": "aa0332b6-23bb-4613-fad3-213029103ec7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 도로명 주소 변환 (서울 데이터)\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = \"/content/juso/seoul.csv\"\n",
        "data = pd.read_csv(\n",
        "    file_path,\n",
        "    encoding='cp949',\n",
        "    sep='|',\n",
        "    usecols=range(13)\n",
        ")\n",
        "\n",
        "# 열 이름 설정\n",
        "data.columns = ['id', 'code', '시도', 'eng_sido', '시군구', 'eng_sigungu', 'unused1', 'unused2',\n",
        "                'road_code', '도로명', 'eng_roadname', 'building_main_no', 'building_sub_no']\n",
        "\n",
        "# 문자열로 변환하고 NaN 값을 빈 문자열로 대체\n",
        "data = data.fillna('').astype(str)\n",
        "\n",
        "# 필요한 열 추출 및 주소 포맷팅\n",
        "def format_address(row):\n",
        "    building_sub_no = str(int(float(row['building_sub_no']))) if row['building_sub_no'] else ''\n",
        "    address_parts = [row['시도'], row['시군구'], row['도로명'], building_sub_no]\n",
        "    formatted_address = \" \".join(part for part in address_parts if part)  # 부분이 비어있지 않으면 포함\n",
        "    return formatted_address\n",
        "\n",
        "data['FormattedAddress'] = data.apply(format_address, axis=1)\n",
        "\n",
        "# 중복된 행 제거\n",
        "data.drop_duplicates(subset='FormattedAddress', keep='first', inplace=True)\n",
        "\n",
        "# 결과 데이터를 새로운 Excel 파일로 저장\n",
        "output_path = \"/content/result/seoul.xlsx\"\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "data.to_excel(output_path, index=False, columns=['FormattedAddress'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceVBiRcsxqnE",
        "outputId": "f5e7f45e-e64b-4fb8-e794-21d78d875baa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-2421bba7f4d2>:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id code     시도 eng_sido  시군구 eng_sigungu unused1 unused2  \\\n",
            "0  135965  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "1  135964  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "2  135964  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "3  135965  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "4  135962  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "\n",
            "        road_code     도로명     eng_roadname building_main_no building_sub_no  \\\n",
            "0  116804166052.0  개포로17길  Gaepo-ro 17-gil              0.0             9.0   \n",
            "1  116804166053.0  개포로20길  Gaepo-ro 20-gil              0.0            25.0   \n",
            "2  116803121022.0     논현로      Nonhyeon-ro              0.0            88.0   \n",
            "3  116803122001.0     개포로         Gaepo-ro              0.0           251.0   \n",
            "4  116803121022.0     논현로      Nonhyeon-ro              0.0            42.0   \n",
            "\n",
            "      FormattedAddress  \n",
            "0   서울특별시 강남구 개포로17길 9  \n",
            "1  서울특별시 강남구 개포로20길 25  \n",
            "2     서울특별시 강남구 논현로 88  \n",
            "3    서울특별시 강남구 개포로 251  \n",
            "4     서울특별시 강남구 논현로 42  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 지역별 데이터를 무작위로 섞음\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 파일 경로 설정\n",
        "excel_path = 'result/location.xlsx'\n",
        "\n",
        "# 엑셀 파일 로드\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# 데이터프레임의 행을 무작위로 섞음\n",
        "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 섞은 데이터 저장\n",
        "output_path = 'result/shuffled_location.xlsx'\n",
        "shuffled_df.to_excel(output_path, index=False)"
      ],
      "metadata": {
        "id": "dXcXgKsaOnUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## title(공고 제목), body(공고 내용) 쌍의 데이터 100만개 생성\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def generate_dataset(num_samples):\n",
        "    job_types = [\n",
        "    # 일상 도움\n",
        "    \"강아지 산책\", \"강아지 발톱 정리\", \"고양이 귀청소\", \"햄스터 톱밥 청소\",\n",
        "    \"화분 분갈이\", \"커튼봉 설치\", \"여행계획\", \"기차 예매\", \"쇼핑 같이\",\n",
        "    \"전화 문의 대신\", \"찢어진 인형 수리\", \"그늘막 설치\", \"모루인형 만들기\",\n",
        "    \"시험장까지 픽업\", \"아이 픽업\",\n",
        "    # 정리 및 청소\n",
        "    \"정리정돈\", \"집 청소\", \"화단 청소\", \"이불 빨래\", \"베란다 창문 닦기\",\n",
        "    \"대형 폐기물 운반\", \"현수막 수거\", \"백화점 오픈런\",\n",
        "    # 물류 및 배송\n",
        "    \"배달\", \"짐 이동\", \"우편물\", \"헬스기구 운반\", \"가게에서 물건 픽업\",\n",
        "    \"터미널 수화물 픽업\", \"굿즈 대리구매\", \"팝업스토어 대리구매\", \"과일포장 작업\",\n",
        "    \"식품 포장\", \"준비물 전달\",\n",
        "    # 기술 작업\n",
        "    \"정비\", \"침대 프레임 조립\", \"시계 약 교체\", \"커튼봉 설치\", \"싱크대 수전 교체\",\n",
        "    \"워셔액 보충\", \"차량 와이퍼 교체\", \"컴퓨터 설치\", \"노트북 수리\", \"증명사진 보정\",\n",
        "    # 매장\n",
        "    \"생일선물 포장\", \"포장\", \"전단지 부착\", \"홍보물부착\",\n",
        "    # 사무 및 교육\n",
        "    \"미술학원 일일 보조 강사\", \"학원 수강생 출석 체크\", \"수업 자료 정리\",\n",
        "    # 행사\n",
        "    \"체육대회 정리\", \"스타벅스 프리퀀시 수령 오픈런\", \"이벤트 장식 설치\",\n",
        "    # 기타\n",
        "    \"단순조립\", \"헤어 모델\", \"고양이 방문 시터\", \"피아노 운반/조율\", \"유튜브 콘텐츠 촬영\",\n",
        "    \"당근마켓 지역 인증\", \"벌집 제거\"\n",
        "]\n",
        "    descriptors = [\n",
        "        \"단순\", \"[바로가능]\", \"오늘\", \"지금\", \"근처 사시는 분\", \"하루만\", \"[30분 소요]\",\n",
        "        \"경험자 우대!\", \"추가 모집\", \"상시\", \"내일\", \"[긴급]\", \"[협의 가능]\", \"쉬워요/\", \"[현장 지급]\",\n",
        "        \"1시간 이하/\", \"[10분컷]\"\n",
        "        ]\n",
        "    actions = [\n",
        "        \"해주실분\", \"해주세요\", \"구합니다\", \"구해요\", \"하실 분 구해요\", \"하실 분 있으신가요?\", \"도와주실 분 찾습니다\",\n",
        "        \"해주실분 찾아요\", \"도와주실 분 구해요\", \"하실 분?\"\n",
        "    ]\n",
        "    details1 = [\n",
        "        \"시간 약속 잘 지키시는 분\", \"경험 있으신 분\", \"금액 제시도 가능합니다\",\n",
        "        \"친구랑 같이 가능\", \"일찍 끝나도 약속한대로 지급\", \"성격이 밝으신 분\", \"초보자 지원하지 말아주세요\",\n",
        "        \"시간 조절 가능\", \"시간/페이 협의 가능\"\n",
        "    ]\n",
        "    details2 = [\n",
        "        \"1명만 모집합니다\", \"오래 하실 수 있는 분 좋아요\", \"자주 하실 수 있으면 좋습니다\", \"댓글로 문의 해주세요~\",\n",
        "        \"승인되시면 전화로 안내드립니다\", \"많이 지원해주세요\", \"자신 있는 분 지원하세요\",\n",
        "        \"현장에서 바로 지급합니다\", \"댓글에 질문 남겨주세요.\", \"승인 후 채팅 답장 부탁합니다.\", \"채팅으로 자세한 시간약속 잡을게요\",\n",
        "        \"장소 이동 가능하신 분이 좋습니다\", \"책임감있게 해주실 분 환영해요\"\n",
        "    ]\n",
        "\n",
        "    selected_job_types = random.choices(job_types, k=num_samples)\n",
        "\n",
        "    titles = [f\"{random.choice(descriptors)} {job_type} {random.choice(actions)}\"\n",
        "              for job_type in selected_job_types]\n",
        "    bodies = [f\"{job_type} {random.choice(details1)} \\n{random.choice(details2)}\"\n",
        "              for job_type in selected_job_types]\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    data = pd.DataFrame({\n",
        "        \"title\": titles,\n",
        "        \"body\": bodies,\n",
        "    })\n",
        "\n",
        "    return data\n",
        "\n",
        "full_dataset = generate_dataset(1000000)\n",
        "\n",
        "sava_path = \"/content/result/title_body.xlsx\"\n",
        "full_dataset.to_excel(sava_path, index=False)"
      ],
      "metadata": {
        "id": "zAFXjW0DYddl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## job_post 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, date, timedelta\n",
        "\n",
        "# 파일 경로\n",
        "input_excel_title_body_path = 'temp/title_body.xlsx'\n",
        "input_excel_location_path = 'temp/shuffled_location.xlsx'\n",
        "output_path = 'result/bulk_insert_job_post.sql'\n",
        "\n",
        "# 파일 로드\n",
        "title_body_df = pd.read_excel(input_excel_title_body_path)\n",
        "locations_df = pd.read_excel(input_excel_location_path)\n",
        "\n",
        "# 지역코드 매핑\n",
        "region_code_map = {\n",
        "    \"서울\": 101,\n",
        "    \"경기\": 102,\n",
        "    \"부산\": 103,\n",
        "    \"경남\": 104,\n",
        "    \"인천\": 105,\n",
        "    \"경북\": 106,\n",
        "    \"대구\": 107,\n",
        "    \"충남\": 108,\n",
        "    \"전남\": 109,\n",
        "    \"전북특별자치도\": 110,\n",
        "    \"충북\": 111,\n",
        "    \"강원특별자치도\": 112,\n",
        "    \"대전\": 113,\n",
        "    \"광주\": 114,\n",
        "    \"울산\": 115,\n",
        "    \"제주특별자치도\": 116,\n",
        "    \"세종특별자치시\": 117\n",
        "}\n",
        "\n",
        "# 날짜 범위 설정\n",
        "start_date = date(2024, 8, 2)\n",
        "end_date = date(2024, 11, 29)\n",
        "date_range = pd.date_range(start_date, end_date).to_pydatetime().tolist()\n",
        "\n",
        "# 데이터 생성\n",
        "created_at = datetime(2024, 7, 31, 17, 0)\n",
        "modified_at = created_at\n",
        "application_count = 0\n",
        "comments_count = 0\n",
        "increment_view_count = 0\n",
        "interests_count = 0\n",
        "closed = False\n",
        "employed = False\n",
        "member_id = 1   # 우선은 1로 둔다(나중에 업데이트 예정)\n",
        "\n",
        "# 데이터 개수 지정\n",
        "num_samples = 1000000\n",
        "\n",
        "# SQL 파일 오픈\n",
        "with open(output_path, 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO job_post (id, created_at, modified_at, application_count, closed, comments_count, deadline, employed, increment_view_count, interests_count, job_start_date, location, title, member_id, region_code) VALUES\\n\")\n",
        "\n",
        "\n",
        "    for i in range(0, num_samples):\n",
        "        deadline = random.choice(date_range)\n",
        "        job_start_date = deadline + timedelta(days=1)\n",
        "        title = title_body_df.iloc[i, 0]\n",
        "        location = locations_df.iloc[i, 0]\n",
        "\n",
        "        # 지역코드 추출\n",
        "        region = location.split()[0]  # 도로명 주소에서 첫 번째 단어는 시,도\n",
        "        region_code = region_code_map.get(region, 999)\n",
        "\n",
        "        # 날짜 포맷을 2024-01-01 형식으로 변경\n",
        "        deadline_str = deadline.strftime('%Y-%m-%d')\n",
        "        job_start_date_str = job_start_date.strftime('%Y-%m-%d')\n",
        "\n",
        "        # 데이터 값을 생성\n",
        "        sql = f\"({i + 1}, '{created_at.strftime('%Y-%m-%d %H:%M:%S.%f')}', '{modified_at.strftime('%Y-%m-%d %H:%M:%S.%f')}', {application_count}, {int(closed)}, {comments_count}, '{deadline_str}', {int(employed)}, {increment_view_count}, {interests_count}, '{job_start_date_str}', '{location}', '{title}', {member_id}, {region_code})\"\n",
        "\n",
        "        # 마지막 데이터가 아니면 쉼표와 줄바꿈 추가\n",
        "        if i < num_samples - 1:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "\n",
        "        file.write(sql)"
      ],
      "metadata": {
        "id": "3VZagFsSOMFJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## job_post_detail 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로\n",
        "excel_title_body_path = 'temp/title_body.xlsx'\n",
        "output_path = 'result/bulk_insert_job_post_detail.sql'\n",
        "\n",
        "# 파일 로드\n",
        "title_body_df = pd.read_excel(excel_title_body_path)\n",
        "\n",
        "# 데이터 개수 지정\n",
        "num_samples = 1000000\n",
        "\n",
        "# 데이터 생성\n",
        "created_at = '2024-07-31 17:00:00.000000'\n",
        "modified_at = '2024-07-31 17:00:00.000000'\n",
        "author = 'user1'  # 우선은 user1로 둔다(나중에 업데이트 예정)\n",
        "\n",
        "# SQL 파일 오픈\n",
        "with open(output_path, 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO job_post_detail (id, created_at, modified_at, author, body, job_post_id) VALUES\\n\")\n",
        "\n",
        "    for i in range(0, num_samples):\n",
        "        body = title_body_df.iloc[i, 1]\n",
        "        job_post_id = i + 1\n",
        "\n",
        "        # 데이터 값을 생성\n",
        "        sql = f\"({i + 1}, '{created_at}', '{modified_at}', '{author}', '{body}', {job_post_id})\"\n",
        "\n",
        "        # 마지막 데이터가 아니면 쉼표와 줄바꿈 추가\n",
        "        if i < num_samples - 1:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "\n",
        "        file.write(sql)"
      ],
      "metadata": {
        "id": "yqscMOHUkxU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## essential 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import random\n",
        "\n",
        "# 파일 경로 설정\n",
        "output_sql_path = 'result/bulk_insert_essential.sql'\n",
        "\n",
        "# 데이터 범위 및 옵션 설정\n",
        "num_samples = 1000000\n",
        "genders = ['UNDEFINED'] * 60 + ['MALE'] * 20 + ['FEMALE'] * 20  # 무관6, 남2, 여2 비율로 설정\n",
        "age_distribution = [0] * 40 + [20] * 30 + [25] * 5 + [30] * 10 + [40] * 5  # 해당 비율로 나이 분포 설정\n",
        "\n",
        "# SQL 파일 생성\n",
        "with open(output_sql_path, 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO essential (id, gender, min_age, job_post_detail_id) VALUES\\n\")\n",
        "\n",
        "    for i in range(1, num_samples + 1):\n",
        "        gender = random.choice(genders)  # 랜덤으로 성별 선택\n",
        "        min_age = random.choice(age_distribution)  # 랜덤으로 나이 선택\n",
        "        job_post_detail_id = i  # 1부터 100만까지 순차적 증가\n",
        "\n",
        "        # 데이터 값을 생성\n",
        "        sql = f\"({i}, '{gender}', {min_age}, {job_post_detail_id})\"\n",
        "\n",
        "        # 마지막 데이터가 아니면 쉼표와 줄바꿈 추가\n",
        "        if i < num_samples:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "\n",
        "        file.write(sql)"
      ],
      "metadata": {
        "id": "doQA95DS-Bj_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## wage 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import random\n",
        "\n",
        "# SQL 파일에서 데이터 읽기\n",
        "def read_sql_file(file_path):\n",
        "    titles = []\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        for line in file:\n",
        "            if line.strip().endswith('),') or line.strip().endswith(');'):  # 데이터가 있는 행인지 확인\n",
        "                parts = line.split(',')\n",
        "                title = parts[12].strip().strip(\"'\")  # 'title' 열의 값을 추출\n",
        "                titles.append(title)\n",
        "    return titles\n",
        "\n",
        "# wage 데이터 생성\n",
        "def generate_wage(title, index):\n",
        "    day_keywords = [\"오늘\", \"지금\", \"하루만\", \"내일\", \"체육대회 정리\", \"헬스기구 운반\", \"일일\", \"그늘막 설치\"]\n",
        "    hour_keywords = [\"30분\", \"1시간\", \"10분컷\", \"시계 약 교체\", \"커튼봉 설치\", \"기차 예매\",\n",
        "                     \"강아지 발톱 정리\", \"고양이 귀청소\", \"햄스터 톱밥 청소\", \"시험장까지 픽업\"]\n",
        "\n",
        "    # pay_basis 설정\n",
        "    if any(keyword in title for keyword in day_keywords):\n",
        "        pay_basis = 'TOTAL_DAYS'\n",
        "        work_days = 1\n",
        "        work_time = 0\n",
        "    elif any(keyword in title for keyword in hour_keywords):\n",
        "        pay_basis = 'TOTAL_HOURS'\n",
        "        work_days = 1\n",
        "        work_time = 1\n",
        "    else:\n",
        "        pay_basis = random.choice(['TOTAL_HOURS'] * 70 + ['TOTAL_DAYS'] * 30)\n",
        "        if pay_basis == 'TOTAL_HOURS':\n",
        "            work_days = 1\n",
        "            work_time = random.choice([1, 2] * 70 + [3, 4, 5] * 20 + [6, 7, 8] * 10)  # 1,2는 70%, 3~5는 20%, 6~8는 10% 비율로 설정\n",
        "        else:\n",
        "            work_days = random.choice([1, 2, 3] * 70 + [4, 5] * 25 + [6, 7] * 5)  # 1~3은 70%, 4,5는 25%, 6,7은 5% 비율로 설정\n",
        "            work_time = 0\n",
        "\n",
        "    # cost 설정\n",
        "    if pay_basis == 'TOTAL_HOURS':\n",
        "        if work_time in [1, 2]:\n",
        "            cost = random.choice(range(10000, 35000, 5000))  # 10000에서 30000까지, 5000 단위\n",
        "        elif work_time in [3, 4, 5]:\n",
        "            cost = random.choice(range(20000, 45000, 5000))  # 20000에서 40000까지, 5000 단위\n",
        "        else:\n",
        "            cost = random.choice(range(40000, 65000, 5000))  # 40000에서 60000까지, 5000 단위\n",
        "    else:\n",
        "        if work_days in [1, 2, 3]:\n",
        "            cost = random.choice(range(20000, 45000, 5000))  # 20000에서 40000까지, 5000 단위\n",
        "        elif work_days in [4, 5]:\n",
        "            cost = random.choice(range(30000, 65000, 5000))  # 30000에서 60000까지, 5000 단위\n",
        "        else:\n",
        "            cost = random.choice(range(40000, 95000, 5000))  # 40000에서 90000까지, 5000 단위\n",
        "\n",
        "    wage_payment_method = random.choice(['INDIVIDUAL_PAYMENT', 'SERVICE_PAYMENT'])\n",
        "    paid = 0  # 모두 false니까 0으로 설정\n",
        "\n",
        "    return f\"({index + 1}, {cost}, {paid}, '{pay_basis}', '{wage_payment_method}', {work_days}, {work_time}, {index + 1}),\\n\"\n",
        "\n",
        "# SQL 파일 쓰기\n",
        "def write_to_sql_file(titles, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(\"INSERT INTO wage (id, cost, paid, pay_basis, wage_payment_method, work_days, work_time, job_post_detail) VALUES\\n\")\n",
        "        for index, title in enumerate(titles):\n",
        "            sql_statement = generate_wage(title, index)\n",
        "            if index < len(titles) - 1:\n",
        "                file.write(sql_statement)\n",
        "            else:\n",
        "                # 마지막 행 처리\n",
        "                file.write(sql_statement[:-2] + \";\\n\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "input_file_path = 'result/bulk_insert_job_post.sql'\n",
        "output_file_path = 'result/bulk_insert_wage.sql'\n",
        "\n",
        "# 파일 읽고 쓰기\n",
        "job_post_titles = read_sql_file(input_file_path)\n",
        "write_to_sql_file(job_post_titles, output_file_path)"
      ],
      "metadata": {
        "id": "jfHucmwRsT8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}